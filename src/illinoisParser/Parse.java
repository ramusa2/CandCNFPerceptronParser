package illinoisParser;

import java.util.ArrayList;
import java.util.HashSet;

import supertagger.LexicalCategoryEntry;
import supertagger.SupertagAssignment;
import supertagger.lewissteedman.LSSupertagger;

import eval.DepSet;

/**
 * A Parse object stores the AUTO string for a parse (whether generated by a parser, or
 * read from a .auto file). That string defines a unique parse tree, along with a unique
 * set of dependencies. This class also provides methods to get the parse's lexical
 * categories, a LaTeX representation of the parse, etc.
 * 
 * @author ramusa2
 *
 */
public class Parse {

	private static Parse EMPTY_PARSE;

	/**
	 * The AUTO string for this parse
	 */
	private final String autoString;

	/**
	 * The AutoDecoder object instantiated with the AUTO parse
	 */
	private final AutoDecoder decoder;

	/**
	 * The parsing model, with a reference to the Grammar object 
	 * used to encode this parse into a Tree object
	 */
	private final Model model;

	/**
	 * The Tree object corresponding to this AUTO parse
	 */
	private final Tree tree;

	/**
	 * The sentence this parse yields
	 */
	private final Sentence sentence;

	/**
	 * Default contructor
	 * @param auto the AUTO string defining this parse
	 */
	public Parse(String auto, Model m, Sentence sen) {
		autoString = auto;
		model = m;
		sentence = sen;
		decoder = new AutoDecoder(sentence, autoString);
		tree = decoder.buildTree(model);
	}

	public Parse(Model m) {
		this.model = m;
		this.sentence = new Sentence();
		this.autoString = "";
		this.decoder = new AutoDecoder(sentence, autoString); 
		this.tree = null;
	}

	public Chart getCoarseChart() {
		return decoder.getCoarseChart(model.grammar);
	}

	public Chart getFineChart() {
		return decoder.getFineChart(model);

	}

	public Tree getTree() {
		return this.tree;
	}

	public String getLaTeXString(boolean isChinese) {
		return this.buildLaTeXString(isChinese);
	}

	private String buildLaTeXString(boolean isChinese) {
		ArrayList<ArrayList<ArrayList<String>>> viterbiParse = new ArrayList<ArrayList<ArrayList<String>>>();
		for (int i = 0; i < sentence.length(); i++) {
			viterbiParse.add(new ArrayList<ArrayList<String>>());
			for (int j = 0; j < sentence.length(); j++) {
				viterbiParse.get(i).add(new ArrayList<String>());
			}
		}
		this.buildTeXCells(viterbiParse, model, tree);
		String s = buildTeX(viterbiParse, sentence, model.grammar, isChinese);	
		return s;
	}


	/**
	 * Recursively fills a "set of cells with strings for TeX"
	 */
	public void buildTeXCells(ArrayList<ArrayList<ArrayList<String>>> viterbiParse,
			Model model, Tree tree) {
		if (tree.B!= null) {
			buildTeXCells(viterbiParse, model, tree.B);
			if (tree.C != null) {
				buildTeXCells(viterbiParse, model, tree.C);
			}
		}
		viterbiParse.get(tree.getX()).get(tree.getY()).add(tree.rule.getType().toString());
		viterbiParse.get(tree.getX()).get(tree.getY()).add(
				model.grammar.prettyCat(tree.A).replaceAll("\\\\\\.","\\\\").replaceAll("/\\.","/").replaceAll("\\\\", "\\\\bs "));
	}

	/**
	 * Builds a TeX Beamer slide with the parse.  Information is extracted from viterbiParse which has
	 * category span information
	 * @param viterbiParse Category span information
	 * @return A TeX Beamer slide
	 */
	public static String buildTeX(ArrayList<ArrayList<ArrayList<String>>> viterbiParse, 
			Sentence sentence, Grammar grammar, boolean isChinese) {
		String TeXParse = "\\begin{frame}\\centering\n" +
				"\\adjustbox{max height=\\dimexpr\\textheight-5.5cm\\relax,\n" +
				"           max width=\\textwidth}{\n";
		// Start at len , 0
		//TeXParse += "viterbi: " + BestTree.prob + "\n";
		TeXParse += "\\deriv{" + sentence.length() + "}{\n";

		if (isChinese) {
			TeXParse += "\\text{\\chinese ";
		} else {
			TeXParse += "{\\rm ";
		}
		TeXParse += Util.escape_chars(sentence.get(0).getWord());

		if (isChinese) {
			TeXParse += "\\stopchinese}";
		} else {
			TeXParse += "}";
		}
		for (int i = 1; i < sentence.length(); i++) {
			if (isChinese) {
				TeXParse += "& \\text{\\chinese ";
			} else {
				TeXParse += "& {\\rm ";
			}
			//TeXParse += Util.escape_chars(sentence.get(0).getWord());
			// TODO: add an asterisk if this word is UNK
			TeXParse += Util.escape_chars(sentence.get(i).getWord());

			if (isChinese) {
				TeXParse += "\\stopchinese}";
			} else {
				TeXParse += "}";
			}
		}
		TeXParse += "\\\\\n";

		TeXParse += "\\uline{1}";
		for (int i = 1; i < sentence.length(); i++) {
			TeXParse += "& \\uline{1}";
		}
		TeXParse += "\\\\\n";

		boolean repeat = false;
		for (int s = 0; s < sentence.length(); s++) {
			int extra = 0;
			for (int i = 0; i < sentence.length() - s; i++) {
				ArrayList<String> strings = viterbiParse.get(i).get(i + s);
				Rule_Type type;
				String cat;
				if (!strings.isEmpty()) {
					if (strings.size() % 2 == 1) {
						cat = Util.escape_chars(strings.remove(0));//
						TeXParse += "\\mc{" + (s + 1) + "}{\\it " + cat + "}";
						extra = s;
					} else {
						type = Rule_Type.valueOf(strings.remove(0));
						TeXParse += Type(type, s + 1);
						if (type.equals(Rule_Type.FW_CONJOIN)) {
							strings.remove(0);
						} else {
							extra = s;
						}
					}
					if (!strings.isEmpty()) {
						repeat = true;
					}
				}
				if (i == sentence.length() - s - 1) {
					TeXParse += "\\\\\n";
				} else if (extra == 0) {
					TeXParse += "\t&";
				} else {
					extra -= 1;
				}
			}
			if (repeat) {
				s -= 1;
				repeat = false;
			}
		}
		TeXParse += "}";
		return TeXParse + "}\n\\end{frame}\n";
	}


	private static String Type(Rule_Type type, int s) {
		switch (type) {
		case FW_APPLY:
			return "\\fapply{" + s + "}";
		case FW_COMPOSE:
		case FW_2_COMPOSE:
		case FW_3_COMPOSE:
			return "\\fcomp{" + s + "}";
		case FW_XCOMPOSE:
			return "\\fxcomp{" + s + "}";
		case BW_APPLY:
			return "\\bapply{" + s + "}";
		case BW_COMPOSE:
		case BW_2_COMPOSE:
		case BW_3_COMPOSE:
			return "\\bcomp{" + s + "}";
		case BW_XCOMPOSE:
			return "\\bxcomp{" + s + "}";
		case TYPE_TOP:
			return "\\comb{" + s + "}{TOP}";
		case FW_PUNCT:
			return "\\comb{" + s + "}{> punc}";
		case BW_PUNCT:
			return "\\comb{" + s + "}{< punc}";
		case FW_CONJOIN:
			return "";
		case BW_CONJOIN:
			return "\\conj{" + s + "}";
		case FW_TYPERAISE:
			return "\\ftype{" + s + "}";
		case BW_TYPERAISE:
			return "\\btype{" + s + "}";
		case TYPE_CHANGE:
			/*
	    case FW_TYPECHANGE:
	    case BW_TYPECHANGE:
	      return "\\comb{" + s + "}{TC}";
			 */
		default:
			return "";
		}
	}

	public String getPargString() {
		return this.buildPargString();
	}

	private String buildPargString() {
		return Tree.buildPargString(this.tree, this.sentence);
	}

	public boolean matches(Parse guessParse) {
		if(this.sentence.length() != guessParse.sentence.length()) {
			return false;
		}
		for(int i=0; i<this.sentence.length(); i++) {
			if(!this.sentence.get(i).getWord().equals(guessParse.sentence.get(i).getWord())) {
				return false;
			}
		}
		return true;
	}

	public boolean isFailure() {
		return this==getEmptyParse(this.model) || this.matches(EMPTY_PARSE);
	}

	public static Parse getEmptyParse(Model m) {
		if(EMPTY_PARSE == null || EMPTY_PARSE.model != m) {
			EMPTY_PARSE = new Parse(m);
		}
		return EMPTY_PARSE;
	}

	public String[] getLexicalCategories() {
		int[] lexIDs = this.tree.getLexicalCategoryIDs();
		String[] lexcats = new String[lexIDs.length];
		for(int i=0; i<lexIDs.length; i++) {
			lexcats[i] = model.grammar.getCatFromID(lexIDs[i]);
		}
		return lexcats;
	}

	public DepSet getPredArgDeps() {
		return DepSet.getDepSetFromPargEntry(this.getPargString());
	}

	public String getLaTeXStringWithTaggerErrors(boolean isChinese,
			HashSet<String> knownCats, LSSupertagger net, double beta) {
		ArrayList<ArrayList<ArrayList<String>>> viterbiParse = new ArrayList<ArrayList<ArrayList<String>>>();
		for (int i = 0; i < sentence.length(); i++) {
			viterbiParse.add(new ArrayList<ArrayList<String>>());
			for (int j = 0; j < sentence.length(); j++) {
				viterbiParse.get(i).add(new ArrayList<String>());
			}
		}
		this.buildTeXCells(viterbiParse, model, tree);
		String s = buildTeXWithTaggerErrors(viterbiParse, sentence, model.grammar, isChinese, knownCats, net, beta);	
		return s;
	}

	private static String CORRECT = "OliveGreen";
	private static String IN_BEAM = "NavyBlue";
	private static String OUTSIDE_BEAM = "YellowOrange";
	private static String MISSING = "Red";
	
	
	/**
	 * Builds a TeX Beamer slide with the parse.  Information is extracted from viterbiParse which has
	 * category span information
	 * @param viterbiParse Category span information
	 * @return A TeX Beamer slide
	 */
	public static String buildTeXWithTaggerErrors(ArrayList<ArrayList<ArrayList<String>>> viterbiParse, 
			Sentence sentence, Grammar grammar, boolean isChinese,
			HashSet<String> knownCats, LSSupertagger net, double beta) {
		String TeXParse = "\\begin{frame}\\centering\n" +
				"\\adjustbox{max height=\\dimexpr\\textheight-5.5cm\\relax,\n" +
				"           max width=\\textwidth}{\n";
		// Start at len , 0
		//TeXParse += "viterbi: " + BestTree.prob + "\n";
		TeXParse += "\\deriv{" + sentence.length() + "}{\n";
		

		SupertagAssignment predictions = net.tagSentence(sentence);
		
		String color = getColor(knownCats, predictions, sentence, 0, beta);

		if (isChinese) {
			TeXParse += "\\text{\\chinese ";
		} else {
			TeXParse += "{\\rm ";
		}
		TeXParse += "\\color{"+color+"} "+ Util.escape_chars(sentence.get(0).getWord());

		if (isChinese) {
			TeXParse += "\\stopchinese}";
		} else {
			TeXParse += "}";
		}
		for (int i = 1; i < sentence.length(); i++) {
			if (isChinese) {
				TeXParse += "& \\text{\\chinese ";
			} else {
				TeXParse += "& {\\rm ";
			}
			color = getColor(knownCats, predictions, sentence, i, beta);
			
			//TeXParse += Util.escape_chars(sentence.get(0).getWord());
			// TODO: add an asterisk if this word is UNK
			TeXParse += "\\color{"+color+"} "+ Util.escape_chars(sentence.get(i).getWord());

			if (isChinese) {
				TeXParse += "\\stopchinese}";
			} else {
				TeXParse += "}";
			}
		}
		TeXParse += "\\\\\n";

		TeXParse += "\\uline{1}";
		for (int i = 1; i < sentence.length(); i++) {
			TeXParse += "& \\uline{1}";
		}
		TeXParse += "\\\\\n";

		boolean repeat = false;
		for (int s = 0; s < sentence.length(); s++) {
			int extra = 0;
			for (int i = 0; i < sentence.length() - s; i++) {
				ArrayList<String> strings = viterbiParse.get(i).get(i + s);
				Rule_Type type;
				String cat;
				if (!strings.isEmpty()) {
					if (strings.size() % 2 == 1) {
						cat = Util.escape_chars(strings.remove(0));//
						TeXParse += "\\mc{" + (s + 1) + "}{\\it " + cat + "}";
						extra = s;
					} else {
						type = Rule_Type.valueOf(strings.remove(0));
						TeXParse += Type(type, s + 1);
						if (type.equals(Rule_Type.FW_CONJOIN)) {
							strings.remove(0);
						} else {
							extra = s;
						}
					}
					if (!strings.isEmpty()) {
						repeat = true;
					}
				}
				if (i == sentence.length() - s - 1) {
					TeXParse += "\\\\\n";
				} else if (extra == 0) {
					TeXParse += "\t&";
				} else {
					extra -= 1;
				}
			}
			if (repeat) {
				s -= 1;
				repeat = false;
			}
		}
		TeXParse += "}";
		return TeXParse + "}\n\\end{frame}\n";
	}

	private static String getColor(HashSet<String> knownCats,
			SupertagAssignment predictions, Sentence sen, int i, double beta) {
		String cat = sen.get(i).getCategory();
		if(knownCats.contains(cat)) {
			LexicalCategoryEntry entry = predictions.getBest(i);
			if(entry.category().equals(cat)) {
				return CORRECT;
			}
			double cutoff = entry.score()*beta;
			for(LexicalCategoryEntry other : predictions.getAll(i)) {
				double score = other.score();
				if(score >= cutoff) {
					return IN_BEAM;
				}
			}
			return OUTSIDE_BEAM;
		}
		else {
			return MISSING;
		}
	}

	public Sentence getSentence() {
		return this.sentence;
	}
}
